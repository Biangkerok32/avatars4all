{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "yarok.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyP1XImDZq7Lpbgi0o9pjC0t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/avatars4all/blob/master/yarok.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_ETOKoCh2ur"
      },
      "source": [
        "# Video Green Screen\n",
        "\n",
        "## Qin et al., U^2-Net: Going Deeper with Nested U-Structure for Salient Object Detection, https://arxiv.org/abs/2005.09007, https://github.com/NathanUA/U-2-Net\n",
        "\n",
        "## Ke et al., MODNet: Is a Green Screen Really Necessary for Real-Time Portrait Matting?, https://arxiv.org/abs/2011.11961, https://github.com/ZHKKKe/MODNet\n",
        "\n",
        "### Made just a little bit more accessible by Eyal Gruss ([@eyaler](twitter.com/eyaler) / [eyalgruss.com](https://eyalgruss.com) / eyalgruss@gmail.com)\n",
        "\n",
        "#### Foreground options:\n",
        "*   Image from web or upload\n",
        "*   Video from web or upload\n",
        "*   Trim video start time and duration\n",
        "*   Override frame height and rate\n",
        "*   Concatenate multiple videos\n",
        "*   Cut to short clips and mix up with options for random effects\n",
        "*   Mirror versions of the above\n",
        "\n",
        "#### Model options:\n",
        "*   U^2-Net\n",
        "*   U^2-Net p (small)\n",
        "*   U^2-Net human segmentation\n",
        "*   MODNet photographic model\n",
        "*   MODNet \"webcam\" model\n",
        "*   U^2-Net portrait generation (sketch)\n",
        "*   U^2-Net portrait generation + U^2-Net blending\n",
        "*   U^2-Net preprocessing + U^2-Net portrait generation\n",
        "*   U^2-Net preprocessing + U^2-Net portrait generation + U^2-Net blending\n",
        "*   similar combinations as above with any of the other U^2-Net models\n",
        "\n",
        "#### Blending options:\n",
        "*   Continuous blending\n",
        "*   One frame delay smoothing with custom threshold\n",
        "*   Grab sketch colors from original foreground\n",
        "\n",
        "#### Background options:\n",
        "*   Solid white, black, chroma green, chroma blue or any hex value\n",
        "*   Transparent (for images)\n",
        "*   Image from web or upload\n",
        "*   Video from web or upload\n",
        "*   Trim video start time and duration\n",
        "*   Override frame height and rate\n",
        "*   Concatenate multiple videos\n",
        "*   Cut to short clips and mix up with options for random effects\n",
        "*   Loop video from start or in reverse\n",
        "*   Resize to match foreground, optionally keeping aspect ratio\n",
        "*   Foreground image/video with optional following effects\n",
        "*   Bokeh (gamma-corrected blurred) versions of the above\n",
        "*   Grayscale versions of the above\n",
        "*   Mirror versions of the above\n",
        "\n",
        "#### Examples:\n",
        "*   U^2-Net/MODNet model comparison: https://twitter.com/eyaler/status/1342853322127110146\n",
        "*   U^2-Net portrait sketching \"Take On Me\": https://twitter.com/eyaler/status/1346395761236443138, https://vimeo.com/showcase/8491391\n",
        "*   Sexy vaporwave lady series: https://youtu.be/74vgrfIVE9A\n",
        "\n",
        "##### A curated list of online generative tools: [j.mp/generativetools](https://j.mp/generativetools)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K5a29Wbgi0L",
        "cellView": "form"
      },
      "source": [
        "#@title Setup\n",
        "%cd /content\n",
        "!git clone --depth 1 https://github.com/eyaler/U-2-Net\n",
        "import os\n",
        "\n",
        "!mkdir -p /content/U-2-Net/saved_models/u2net\n",
        "%cd /content/U-2-Net/saved_models/u2net\n",
        "if not os.path.exists('/content/U-2-Net/saved_models/u2net/u2net.pth'):\n",
        "  !gdown https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ -O /content/U-2-Net/saved_models/u2net/u2net.pth\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/u2net.pth\n",
        "\n",
        "!mkdir -p /content/U-2-Net/saved_models/u2netp\n",
        "%cd /content/U-2-Net/saved_models/u2netp\n",
        "if not os.path.exists('/content/U-2-Net/saved_models/u2netp/u2netp.pth'):\n",
        "  !gdown https://drive.google.com/uc?id=1rbSTGKAE-MTxBYHd-51l2hMOQPT_7EPy -O /content/U-2-Net/saved_models/u2netp/u2netp.pth\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/u2netp.pth\n",
        "\n",
        "!mkdir -p /content/U-2-Net/saved_models/u2net_human_seg\n",
        "%cd /content/U-2-Net/saved_models/u2net_human_seg\n",
        "if not os.path.exists('/content/U-2-Net/saved_models/u2net_human_seg/u2net_human_seg.pth'):\n",
        "  !gdown https://drive.google.com/uc?id=1-Yg0cxgrNhHP-016FPdp902BR-kSsA4P -O /content/U-2-Net/saved_models/u2net_human_seg/u2net_human_seg.pth\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/u2net_human_seg.pth\n",
        "\n",
        "!mkdir -p /content/U-2-Net/saved_models/u2net_portrait\n",
        "%cd /content/U-2-Net/saved_models/u2net_portrait\n",
        "if not os.path.exists('/content/U-2-Net/saved_models/u2net_portrait/u2net_portrait.pth'):\n",
        "  !gdown  -O /content/U-2-Net/saved_models/u2net_portrait/u2net_portrait.pth\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/u2net_portrait.pth\n",
        "\n",
        "%cd /content\n",
        "!git clone --depth 1 https://github.com/eyaler/MODNet\n",
        "%cd MODNet/pretrained\n",
        "\n",
        "if not os.path.exists('/content/MODNet/pretrained/modnet_photographic_portrait_matting.ckpt'):\n",
        "  !gdown https://drive.google.com/uc?id=1mcr7ALciuAsHCpLnrtG_eop5-EYhbCmz -O /content/MODNet/pretrained/modnet_photographic_portrait_matting.ckpt\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/modnet_photographic_portrait_matting.ckpt\n",
        "\n",
        "if not os.path.exists('/content/MODNet/pretrained/modnet_webcam_portrait_matting.ckpt'):\n",
        "  !gdown https://drive.google.com/uc?id=1Nf1ZxeJZJL8Qx9KadcYYyEmmlKhTADxX -O /content/MODNet/pretrained/modnet_webcam_portrait_matting.ckpt\n",
        "!wget --no-check-certificate -nc https://eyalgruss.com/fomm/modnet_webcam_portrait_matting.ckpt\n",
        "\n",
        "%cd /content\n",
        "!pip install -U youtube-dl\n",
        "!pip install -U imageio\n",
        "!pip install -U imageio-ffmpeg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGtTGhKUh1fW",
        "cellView": "form"
      },
      "source": [
        "#@title Get the foreground image/video and background image/video from the web\n",
        "#@markdown 1. You can change the URLs to your **own** stuff!\n",
        "#@markdown 2. For the background you can use the drop-down menu to alternatively choose a **solid color**, **transparent** (for images only) or the **foreground** iteslf (with optional effects). You can also feed a **hex** color value (e.g. de0000 or #de0000)\n",
        "#@markdown 3. Advanced: You can mannualy upload files and put in the path to the location on Colab. This path can also be to a folder containing **several videos**.\n",
        "#@markdown 4. Alternatively, you can upload **local** files in the next cells\n",
        "\n",
        "#foreground_url = 'https://www.youtube.com/watch?v=HzpzvAPj1kw' #@param {type:\"string\"}\n",
        "#background_url = 'https://www.youtube.com/watch?v=pXpvh6eIFBk' #@param ['White', 'Black', 'Chroma Green', 'Chroma Blue', 'Transparent', 'Foreground'] {allow-input: true}\n",
        "\n",
        "#foreground_url = 'https://www.youtube.com/watch?v=kMpnwIGDQvU' #@param {type:\"string\"}\n",
        "#background_url = 'https://www.youtube.com/watch?v=dMvnCyznteU' #@param ['White', 'Black', 'Chroma Green', 'Chroma Blue', 'Transparent', 'Foreground'] {allow-input: true}\n",
        "\n",
        "foreground_url = 'https://www.youtube.com/watch?v=kMpnwIGDQvU' #@param {type:\"string\"}\n",
        "background_url = 'https://www.youtube.com/watch?v=dMvnCyznteU' #@param ['White', 'Black', 'Chroma Green', 'Chroma Blue', 'Transparent', 'Foreground'] {allow-input: true}\n",
        "\n",
        "import os\n",
        "import youtube_dl\n",
        "def is_supported(url):\n",
        "    if url.lower().endswith(('.png','.jpg','.jpeg','.bmp')):\n",
        "      return False\n",
        "    extractors = youtube_dl.extractor.gen_extractors()\n",
        "    for e in extractors:\n",
        "        if e.suitable(url) and e.IE_NAME != 'generic':\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "if foreground_url:\n",
        "  !rm -f /content/foreground\n",
        "  %cd /content\n",
        "  if os.path.isfile(foreground_url):\n",
        "    foreground_url = [os.path.abspath(foreground_url)]\n",
        "  elif os.path.isdir(foreground_url):\n",
        "    foreground_url = sorted(os.path.join(os.path.abspath(foreground_url),file) for file in os.listdir(foreground_url))\n",
        "  else:\n",
        "    if is_supported(foreground_url):\n",
        "      !rm -f /content/foreground.mp4\n",
        "      !youtube-dl -f 'bestvideo[ext=mp4][vcodec!*=av01]+bestaudio[ext=m4a]/mp4' '$foreground_url' --merge-output-format mp4 -o /content/foreground\n",
        "      !mv /content/foreground.mp4 /content/foreground\n",
        "    if not os.path.exists('/content/foreground'):\n",
        "      !wget '$foreground_url' -O /content/foreground\n",
        "    foreground_url = ['/content/foreground']\n",
        "\n",
        "if '/' in background_url or '.' in background_url or '\\\\' in background_url:\n",
        "  !rm -f /content/background\n",
        "  %cd /content\n",
        "  if os.path.isfile(background_url):\n",
        "    background_url = [os.path.abspath(background_url)]\n",
        "  elif os.path.isdir(background_url):\n",
        "    background_url = sorted(os.path.join(os.path.abspath(background_url),file) for file in os.listdir(background_url))\n",
        "  else:\n",
        "    if is_supported(background_url):\n",
        "      !rm -f /content/background.mp4\n",
        "      !youtube-dl -f 'bestvideo[ext=mp4][vcodec!*=av01]+bestaudio[ext=m4a]/mp4' '$background_url' --merge-output-format mp4 -o /content/background\n",
        "      !mv /content/background.mp4 /content/background\n",
        "    if not os.path.exists('/content/background'):\n",
        "      !wget '$background_url' -O /content/background\n",
        "    background_url = ['/content/background']\n",
        "else:\n",
        "  background_url = background_url.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hrx-hEY-ir8K",
        "cellView": "form"
      },
      "source": [
        "#@title Optionally upload foreground image/video/videos { run: \"auto\" }\n",
        "manually_upload_foreground = False #@param {type:\"boolean\"}\n",
        "if manually_upload_foreground:\n",
        "  from google.colab import files\n",
        "\n",
        "  %cd /content/sample_data\n",
        "  try:\n",
        "    uploaded = files.upload()\n",
        "  except Exception as e:\n",
        "    %cd /content\n",
        "    raise e\n",
        "\n",
        "  foreground_url = sorted(os.path.join(os.path.abspath(file),file) for file in uploaded)\n",
        "  %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4mryuGkitnR",
        "cellView": "form"
      },
      "source": [
        "#@title Optionally upload local background image/video/videos { run: \"auto\" }\n",
        "manually_upload_background = False #@param {type:\"boolean\"}\n",
        "if manually_upload_background:\n",
        "  from google.colab import files\n",
        "\n",
        "  %cd /content/sample_data\n",
        "  try:\n",
        "    uploaded = files.upload()\n",
        "  except Exception as e:\n",
        "    %cd /content\n",
        "    raise e\n",
        "\n",
        "  background_url = sorted(os.path.join(os.path.abspath(file),file) for file in uploaded)\n",
        "  %cd /content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8otpdxD88FH",
        "cellView": "form"
      },
      "source": [
        "#@title Green that screen!\n",
        "#@markdown Model notes:\n",
        "#@markdown 1. u2net tends to remove more unwanted parts, but may also remove desired parts of the foreground objects.\n",
        "#@markdown 2. modnet tends to keep more of the desired parts and also gives a finer boundary, but may leave in more unwanted parts (which is the more useful option if you further post edit the video).\n",
        "#@markdown 3. u2net_portrait will generate a sketch + if background is image/video/\"Foreground\" then use u2net mask of the original foreground to blend with that background.\n",
        "#@markdown 4. u2net + u2net_portrait adds a preprocessing stage to remove the background before generating a sketch of the foreground.\n",
        "#@markdown\n",
        "#@markdown Sketching notes:\n",
        "#@markdown 1. background=\"White\" + model=\"u2net_portrait\" -> everything becomes a sketch\n",
        "#@markdown 2. background=\"Foreground\" + model=\"u2net_portrait\" -> sketched foreground on top of original background\n",
        "#@markdown 3. background=\"White\" + model=\"u2net + u2net_portrait\" -> sketched foreground with white background\n",
        "#@markdown 4. background=\"Foreground\" + model=\"u2net + u2net_portrait\" -> variation similar to (2)\n",
        "#@markdown 5. background=upload result of (1) + model=\"u2net\" -> original foreground on top of sketched background  \n",
        "\n",
        "model = 'u2net' #@param ['u2net', 'modnet_photographic', 'modnet_webcam', 'u2net_portrait', 'u2net + u2net_portrait']\n",
        "u2net_variant = 'u2net' #@param ['u2net', 'u2netp', 'u2net_human_seg']\n",
        "sketch_color = 'Gray' #@param ['Gray','Foreground','Tint outline','Tint fill']\n",
        "one_frame_delay = True #@param {type:\"boolean\"} \n",
        "one_frame_delay_threshold = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "start_secs_foreground = 0#@param {type:\"number\"}\n",
        "duration_secs_foreground = 60#@param {type:\"number\"}\n",
        "start_secs_background = 0#@param {type:\"number\"}\n",
        "duration_secs_background = 60#@param {type:\"number\"}\n",
        "mirror_foreground = False #@param {type:\"boolean\"} \n",
        "mirror_background = False #@param {type:\"boolean\"} \n",
        "gray_background = False #@param {type:\"boolean\"} \n",
        "bokeh_background = False #@param {type:\"boolean\"} \n",
        "bokeh_prcnt = 5 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "bokeh_gamma = 5 #@param {type:\"slider\", min:1, max:50, step:1}\n",
        "keep_aspect_background = True #@param {type:\"boolean\"}\n",
        "loop_reverse_background = False #@param {type:\"boolean\"}\n",
        "override_height_pre = 0#@param {type:\"integer\"}\n",
        "override_height_post = 0#@param {type:\"integer\"}\n",
        "override_fps = 0#@param {type:\"number\"}\n",
        "cut_mix_min_secs_foreground = 0#@param {type:\"number\"}\n",
        "cut_mix_max_secs_foreground = 0#@param {type:\"number\"}\n",
        "cut_mix_tied_background = False #@param {type:\"boolean\"}\n",
        "cut_mix_min_secs_background = 0#@param {type:\"number\"}\n",
        "cut_mix_max_secs_background = 0#@param {type:\"number\"}\n",
        "cut_mix_phase_secs_background = 0#@param {type:\"number\"}\n",
        "#cut_mix_horizontal_flip_prob = 0#@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "#cut_mix_vertical_flip_prob = 0#@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "cut_mix_temporal_flip_prob = 0#@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "copy_audio = True #@param {type:\"boolean\"}\n",
        "\n",
        "bg_mode_max_w = 1920\n",
        "chroma_thresholds = [0.5,0.25]\n",
        "sketch_color = sketch_color.lower()\n",
        "\n",
        "start_secs_foreground = max(start_secs_foreground,0)\n",
        "duration_secs_foreground = max(duration_secs_foreground,0)\n",
        "fg_time_params = ''\n",
        "if duration_secs_foreground: \n",
        "  fg_time_params = '-ss %f -t %f'%(start_secs_foreground, duration_secs_foreground)\n",
        "\n",
        "start_secs_background = max(start_secs_background,0)\n",
        "duration_secs_background = max(duration_secs_background,0)\n",
        "bg_time_params = ''\n",
        "if duration_secs_background: \n",
        "  bg_time_params = '-ss %f -t %f'%(start_secs_background, duration_secs_background)\n",
        "\n",
        "override_height_pre = max(override_height_pre, 0)\n",
        "override_height_post = max(override_height_post, 0)\n",
        "override_fps = max(override_fps, 0)\n",
        "cut_mix_min_secs_foreground = max(cut_mix_min_secs_foreground, 0)\n",
        "cut_mix_max_secs_foreground = max(cut_mix_min_secs_foreground, cut_mix_min_secs_background)\n",
        "cut_mix_min_secs_background = max(cut_mix_min_secs_background, 0)\n",
        "cut_mix_max_secs_background = max(cut_mix_min_secs_background, cut_mix_min_secs_background)\n",
        "if cut_mix_tied_background:\n",
        "  cut_mix_min_secs_background = 0\n",
        "  cut_mix_max_secs_background = 0\n",
        "  cut_mix_phase_secs_background = 0\n",
        "\n",
        "%cd /content\n",
        "\n",
        "fg_dirs = {\n",
        "  'u2net': '/content/U-2-Net/test_data/test_images', \n",
        "  'u2netp': '/content/U-2-Net/test_data/test_images', \n",
        "  'u2net_human_seg': '/content/U-2-Net/test_data/test_human_images'\n",
        "}\n",
        "\n",
        "mask_dirs = {\n",
        "  'u2net': '/content/U-2-Net/test_data/u2net_results', \n",
        "  'u2netp': '/content/U-2-Net/test_data/u2netp_results', \n",
        "  'u2net_human_seg': '/content/U-2-Net/test_data/test_human_images_results'\n",
        "}\n",
        "\n",
        "bg_dir = '/content/bg_frames'\n",
        "result_dir = '/content/out_frames'\n",
        "portrait_in_dir = '/content/U-2-Net/test_data/test_portrait_images/portrait_im'\n",
        "portrait_out_dir = '/content/U-2-Net/test_data/test_portrait_images/portrait_results'\n",
        "for k in fg_dirs:\n",
        "  fg_dir = fg_dirs[k]\n",
        "  mask_dir = mask_dirs[k]\n",
        "  !rm -rf $fg_dir\n",
        "  !mkdir -p $fg_dir\n",
        "  !rm -rf $mask_dir\n",
        "  !mkdir -p $mask_dir\n",
        "!rm -rf $bg_dir\n",
        "!mkdir -p $bg_dir\n",
        "!rm -rf $result_dir\n",
        "!mkdir -p $result_dir\n",
        "!rm -rf $portrait_in_dir\n",
        "!mkdir -p $portrait_in_dir\n",
        "!rm -rf $portrait_out_dir\n",
        "!mkdir -p $portrait_out_dir\n",
        "\n",
        "fg_dir = fg_dirs[u2net_variant]\n",
        "mask_dir = mask_dirs[u2net_variant]\n",
        "\n",
        "import imageio\n",
        "imageio.plugins.freeimage.download()\n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import glob\n",
        "from time import time\n",
        "import io\n",
        "import PIL\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from MODNet.src.models.modnet import MODNet\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "np.random.seed(0)\n",
        "\n",
        "torch_transforms = transforms.Compose(\n",
        "  [\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "  ]\n",
        ")\n",
        "\n",
        "def fix_dims(im):\n",
        "    if im.ndim == 2:\n",
        "        im = np.tile(im[..., None], [1, 1, 3])\n",
        "    return im[...,:3]\n",
        "\n",
        "def crop_resize(im, size, crop=False):\n",
        "  if im.shape[:2] == size:\n",
        "    return im\n",
        "  if size[0]==-1:\n",
        "    size = (int(round(im.shape[0]/im.shape[1]*size[1])), size[1])\n",
        "  elif size[1]==-1:\n",
        "    size = (size[0], int(round(im.shape[1]/im.shape[0]*size[0])))\n",
        "  if size[0]<im.shape[0] or size[1]<im.shape[1]:\n",
        "    interp = cv2.INTER_AREA\n",
        "  else:\n",
        "    interp = cv2.INTER_CUBIC\n",
        "  if not crop:\n",
        "    return np.clip(cv2.resize(im, size[::-1], interpolation=interp),0,1)\n",
        "  ratio = max(size[0]/im.shape[0], size[1]/im.shape[1])\n",
        "  im = np.clip(cv2.resize(im, (int(np.ceil(im.shape[1]*ratio)), int(np.ceil(im.shape[0]*ratio))), interpolation=interp),0,1)\n",
        "  return im[(im.shape[0]-size[0])//2:(im.shape[0]-size[0])//2+size[0], (im.shape[1]-size[1])//2:(im.shape[1]-size[1])//2+size[1]]\n",
        "\n",
        "ref_size = 512\n",
        "def modnet_matting(modnet, im):\n",
        "  im_h, im_w = im.shape[:2]\n",
        "  im_tensor = torch_transforms(im).float()\n",
        "  im_tensor = im_tensor[None, :, :, :].cuda()\n",
        "  \n",
        "  if max(im_h, im_w) < ref_size or min(im_h, im_w) > ref_size:\n",
        "    if im_w >= im_h:\n",
        "      im_rh = ref_size\n",
        "      im_rw = int(im_w / im_h * ref_size)\n",
        "    elif im_w < im_h:\n",
        "      im_rw = ref_size\n",
        "      im_rh = int(im_h / im_w * ref_size)\n",
        "  else:\n",
        "    im_rh = im_h\n",
        "    im_rw = im_w\n",
        "        \n",
        "  im_rw = im_rw - im_rw % 32\n",
        "  im_rh = im_rh - im_rh % 32\n",
        "  \n",
        "  if im_h!=im_rh or im_w!=im_rw:\n",
        "    im_tensor = F.interpolate(im_tensor, size=(im_rh, im_rw), mode='area')\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    _, _, matte_tensor = modnet(im_tensor, True)\n",
        "  matte_tensor = F.interpolate(matte_tensor, size=(im_h, im_w), mode='area')\n",
        "  matte_tensor = matte_tensor.repeat(1, 3, 1, 1)\n",
        "  return matte_tensor[0].data.cpu().numpy().transpose(1, 2, 0)\n",
        "\n",
        "def get_files(folder, fps, cut_mix_min_secs=0, cut_mix_max_secs=0, cut_mix_phase_secs=0):\n",
        "  files = [x for x in sorted(os.listdir(folder)) if x.endswith('.png')]\n",
        "  if not fps or not cut_mix_max_secs:\n",
        "    return files\n",
        "  cuts = []\n",
        "  start = []\n",
        "  frames = int(round(cut_mix_phase_secs*fps))\n",
        "  start = files[:frames]\n",
        "  files = files[frames:]\n",
        "  while len(files):\n",
        "    frames = np.random.randint(round(cut_mix_min_secs*fps),round(cut_mix_max_secs*fps)+1)\n",
        "    cuts.append(files[:frames])\n",
        "    if np.random.random()<cut_mix_temporal_flip_prob:\n",
        "      cuts[-1] = cuts[-1][::-1]\n",
        "    files = files[frames:]\n",
        "  np.random.shuffle(cuts)\n",
        "  return start+[file for sublist in cuts for file in sublist]\n",
        "\n",
        "grand_start = time()\n",
        "start = time()\n",
        "try:\n",
        "    fg_now = imageio.imread(foreground_url[0])\n",
        "    fg_now = fix_dims(fg_now)\n",
        "    if override_height_pre:\n",
        "      fg_now = crop_resize(fg_now, (override_height_pre,-1))\n",
        "    imageio.imwrite(os.path.join(fg_dir,'frame_%05d.png'%1), fg_now, format='PNG-FI')\n",
        "    fg_now = fg_now/255\n",
        "except Exception:\n",
        "    for fg_file in foreground_url:\n",
        "      vf_args = ''\n",
        "      if override_height_pre or override_fps:\n",
        "        args = []\n",
        "        if override_height_pre:\n",
        "          args.append('scale=-1:%d'%override_height_pre)\n",
        "        if override_fps:\n",
        "          args.append('fps=%f'%override_fps)\n",
        "        vf_args = '-vf \"%s\"'%','.join(args)\n",
        "      j = len(glob.glob('%s/frame_*'%fg_dir))\n",
        "      try:\n",
        "        !ffmpeg $fg_time_params -i $fg_file $vf_args -start_number $j $fg_dir/frame_%05d.png\n",
        "        if not override_fps:\n",
        "          with imageio.get_reader(fg_file, format='mp4') as reader:\n",
        "            override_fps = reader.get_meta_data()['fps']\n",
        "      except Exception:\n",
        "        pass\n",
        "    fg_now = imageio.imread(os.path.join(fg_dir,'frame_%05d.png'%1), format='PNG-FI')\n",
        "fg_files = get_files(fg_dir, override_fps, cut_mix_min_secs_foreground, cut_mix_max_secs_foreground, max(-cut_mix_phase_secs_background,0))\n",
        "\n",
        "prepare_time = time()-start\n",
        "\n",
        "start = time()\n",
        "have_u2_mask = False\n",
        "if model.startswith('u2net') and (model!='u2net_portrait' or type(background_url)==list or background_url=='foreground'):\n",
        "  %cd /content/U-2-Net\n",
        "  if u2net_variant == 'u2net_human_seg':\n",
        "    !python /content/U-2-Net/u2net_human_seg_test.py\n",
        "  else:\n",
        "    !python /content/U-2-Net/u2net_test.py $u2net_variant\n",
        "  have_u2_mask = True\n",
        "elif model.startswith('modnet'):\n",
        "  %cd /content/MODNet\n",
        "  modnet = MODNet(backbone_pretrained=False)\n",
        "  modnet = nn.DataParallel(modnet).cuda()\n",
        "  modnet.load_state_dict(torch.load(os.path.join('/content/MODNet/pretrained',model+'_portrait_matting.ckpt')))\n",
        "  modnet.eval()\n",
        "mask_time = time()-start\n",
        "\n",
        "blend_time = 0\n",
        "is_fg = True\n",
        "bg_files = []\n",
        "iter_files = fg_files\n",
        "rounds = 0\n",
        "\n",
        "def preproc_bg(bg, fg_now, bokeh=False, gray=False, flip_x=False, flip_y=False):\n",
        "  bg = crop_resize(bg, fg_now.shape[:2], crop=keep_aspect_background)\n",
        "  if bokeh:\n",
        "    if bokeh_gamma>1:\n",
        "      bg = bg**bokeh_gamma\n",
        "    radius = int(bokeh_prcnt/100*np.sqrt(bg.shape[0]*bg.shape[1])//2*2+1)\n",
        "    if radius>1:\n",
        "      bg = cv2.GaussianBlur(bg,(radius,radius),0)\n",
        "    if bokeh_gamma>1:\n",
        "      bg **= 1/bokeh_gamma\n",
        "  if gray:\n",
        "    bg = fix_dims(np.dot(bg, [0.2989, 0.5870, 0.1140]))\n",
        "  if flip_x:\n",
        "    bg = np.fliplr(bg)\n",
        "  if flip_y:\n",
        "    bg = np.flipud(bg)\n",
        "  return bg\n",
        "\n",
        "def mat(in_dir, out_dir, bg_mode, orig_dir=None, is_pre=False):\n",
        "  global prepare_time, blend_time, fg_now, is_fg, bg_files, iter_files, rounds, override_fps\n",
        "  first_size = fg_now.shape[:2]\n",
        "  rounds += 1\n",
        "  start = time()\n",
        "  if bg_mode == 'white':\n",
        "    bg = np.full_like(fg_now, 1)\n",
        "  elif bg_mode == 'black':\n",
        "    bg = np.full_like(fg_now, 0)\n",
        "  elif bg_mode == 'chroma green':\n",
        "    bg = np.full_like(fg_now, [0,177/255,64/255])\n",
        "  elif bg_mode == 'chroma blue':\n",
        "    bg = np.full_like(fg_now, [0,71/255,187/255])\n",
        "  elif type(bg_mode)==list:\n",
        "    try:\n",
        "      bg = imageio.imread(bg_mode[0])/255\n",
        "      bg = fix_dims(bg)\n",
        "      bg = preproc_bg(bg, fg_now, bokeh=bokeh_background, gray=gray_background, flip_x=mirror_background, flip_y=False)\n",
        "    except Exception:\n",
        "      for bg_file in bg_mode:\n",
        "        vf_args = ''\n",
        "        if override_height_pre or override_fps:\n",
        "          args = []\n",
        "          if override_height_pre:\n",
        "            args.append('scale=-1:%d'%override_height_pre)\n",
        "          if override_fps:\n",
        "            args.append('fps=%f'%override_fps)\n",
        "          vf_args = '-vf \"%s\"'%','.join(args)\n",
        "        j = len(glob.glob('%s/frame_*'%bg_dir))\n",
        "        try:\n",
        "          !ffmpeg $bg_time_params -i $bg_file $vf_args -start_number $j $bg_dir/frame_%05d.png\n",
        "          if not override_fps:\n",
        "            with imageio.get_reader(bg_file, format='mp4') as reader:\n",
        "              override_fps = reader.get_meta_data()['fps']\n",
        "        except Exception:\n",
        "          pass\n",
        "  elif bg_mode not in ['transparent','foreground']:\n",
        "    bg = np.full_like(fg_now, [int(bg_mode.lstrip('#')[i:i+2], 16)/255 for i in [0, 2, 4]])\n",
        "  use_bg_dir = bg_dir\n",
        "  if bg_mode=='foreground' and len(fg_files)>1 and not cut_mix_tied_background and (cut_mix_max_secs_foreground or cut_mix_max_secs_background):\n",
        "    use_bg_dir = fg_dir\n",
        "  bg_files = get_files(use_bg_dir, override_fps, cut_mix_min_secs_background, cut_mix_max_secs_background, max(cut_mix_phase_secs_background,0))\n",
        "  prepare_time += time()-start\n",
        "\n",
        "  start = time()\n",
        "  fg_plus = None\n",
        "  mask_plus = None\n",
        "  orig = None\n",
        "  is_fg = len(fg_files)>1 or not bg_files\n",
        "  if is_fg:\n",
        "    iter_files = fg_files\n",
        "  else:\n",
        "    iter_files = bg_files\n",
        "    fg_now = imageio.imread(os.path.join(in_dir,'frame_%05d.png'%1), format='PNG-FI')/255\n",
        "    if have_u2_mask:\n",
        "      mask = imageio.imread(os.path.join(mask_dir,'frame_%05d.png'%1), format='PNG-FI')/255\n",
        "    elif model.startswith('modnet'):\n",
        "      mask = modnet_matting(modnet, fg_now)\n",
        "    else:\n",
        "      mask = np.ones_like(fg_now)\n",
        "    if orig_dir is not None:\n",
        "      orig = imageio.imread(os.path.join(orig_dir,'frame_%05d.png'%1), format='PNG-FI')/255\n",
        "    if mirror_foreground: #this will only happen on last pass\n",
        "      fg_now = np.fliplr(fg_now)\n",
        "      mask = np.fliplr(mask)\n",
        "      if orig is not None:\n",
        "        orig = np.fliplr(orig)\n",
        "\n",
        "  j = -1\n",
        "  j_direction = 1\n",
        "  for i,file in enumerate(iter_files):\n",
        "      first = i==0 or int(iter_files[i-1].rsplit('_',1)[1].split('.')[0])!=i-1\n",
        "      last = i==len(iter_files)-1 or int(iter_files[i+1].rsplit('_',1)[1].split('.')[0])!=i+1\n",
        "      if is_fg:\n",
        "        if one_frame_delay and not first and not last:\n",
        "          fg_now = fg_plus\n",
        "          mask_minus = mask_now\n",
        "          mask_now = mask_plus\n",
        "          if fg_now is None:\n",
        "            fg_now = imageio.imread(os.path.join(in_dir,file),format='PNG-FI')/255\n",
        "          if have_u2_mask:\n",
        "            if mask_now is None:\n",
        "              mask_now = imageio.imread(os.path.join(mask_dir,file),format='PNG-FI')/255\n",
        "            mask_plus = imageio.imread(os.path.join(mask_dir,fg_files[i+1]),format='PNG-FI')/255\n",
        "          elif model.startswith('modnet'):\n",
        "            if mask_now is None:\n",
        "              mask_now = modnet_matting(modnet, fg_now)\n",
        "            fg_plus = imageio.imread(os.path.join(in_dir,fg_files[i+1]),format='PNG-FI')/255\n",
        "            mask_plus = modnet_matting(modnet, fg_plus)\n",
        "          else:\n",
        "            if mask_now is None:\n",
        "              mask_now = np.ones_like(fg_now)\n",
        "            mask_plus = np.ones_like(fg_now)          \n",
        "          cond = (np.abs(mask_plus-mask_minus)<=one_frame_delay_threshold) & (np.abs(mask_now-mask_minus)>one_frame_delay_threshold) & (np.abs(mask_now-mask_plus)>one_frame_delay_threshold)\n",
        "          mask = mask_now*(1-cond) + (mask_minus+mask_plus)/2*cond\n",
        "        else:\n",
        "          fg_now = imageio.imread(os.path.join(in_dir,file),format='PNG-FI')/255\n",
        "          if have_u2_mask:\n",
        "            mask_now = imageio.imread(os.path.join(mask_dir,file),format='PNG-FI')/255\n",
        "          elif model.startswith('modnet'):\n",
        "            mask_now = modnet_matting(modnet, fg_now)\n",
        "          else:\n",
        "            mask_now = np.ones_like(fg_now)\n",
        "          mask = mask_now\n",
        "\n",
        "        if orig_dir is not None:  \n",
        "          orig = imageio.imread(os.path.join(orig_dir,file),format='PNG-FI')/255\n",
        "        if mirror_foreground and not is_pre:\n",
        "            fg_now = np.fliplr(fg_now)\n",
        "            mask = np.fliplr(mask)\n",
        "            if orig is not None:\n",
        "              orig = np.fliplr(orig)\n",
        "        if bg_mode=='foreground' and (len(fg_files)==1 or cut_mix_tied_background or not cut_mix_max_secs_foreground and not cut_mix_max_secs_background):\n",
        "          if orig is not None:\n",
        "            bg = orig\n",
        "          else:\n",
        "            bg = fg_now\n",
        "        elif bg_files:\n",
        "          if loop_reverse_background: \n",
        "            j += j_direction\n",
        "            if j>=len(bg_files):\n",
        "              j = 2*len(bg_files)-j-1\n",
        "              j_direction = -1\n",
        "            elif j<0:\n",
        "              j = 0\n",
        "              j_direction = 1\n",
        "          else:\n",
        "            j = i%len(bg_files)\n",
        "          bg = imageio.imread(os.path.join(bg_dir,bg_files[j]),format='PNG-FI')/255\n",
        "      \n",
        "      else:\n",
        "        bg = imageio.imread(os.path.join(bg_dir,file),format='PNG-FI')/255\n",
        "      if bg_files:\n",
        "        bg = preproc_bg(bg, fg_now, bokeh=bokeh_background, gray=gray_background, flip_x=mirror_background, flip_y=False)\n",
        "      if bg_mode == 'transparent':\n",
        "        im = np.dstack([fg_now,mask[:,:,0]])\n",
        "      else:\n",
        "        fg = fg_now\n",
        "        if orig is not None:\n",
        "          if sketch_color=='foreground':\n",
        "            fg = 1-(1-fg)*(1-orig)\n",
        "          elif 'tint' in sketch_color:\n",
        "            non_black_mask = np.any(mask != [0, 0, 0], axis=-1)\n",
        "            colors = (orig*mask)[non_black_mask]\n",
        "            chroma = np.max(colors, axis=-1)-np.min(colors, axis=-1)\n",
        "            chroma_thresholds.sort(reverse=True)\n",
        "            if sketch_color=='tint fill':\n",
        "              chroma_thresholds.append(0)\n",
        "            else:\n",
        "              color = np.array([0,0,0])\n",
        "            for threshold in chroma_thresholds:\n",
        "              cond = chroma>=threshold\n",
        "              if np.any(cond):\n",
        "                unique, counts = np.unique(colors[cond], axis=0, return_counts=True)\n",
        "                color = unique[np.argmax(counts)]\n",
        "                break\n",
        "            if sketch_color=='tint outline':\n",
        "              fg = 1-(1-fg)*(1-color)\n",
        "            elif sketch_color=='tint fill':\n",
        "              fg = fg*color\n",
        "        im = bg*(1-mask)+fg*mask\n",
        "      if im.shape[:2]!=first_size:\n",
        "        im = crop_resize(im, first_size)\n",
        "      if override_height_post and not is_pre:\n",
        "        im = crop_resize(im, (override_height_post,-1))\n",
        "      elif not is_fg and bg_mode_max_w and fg_now.shape[1]>bg_mode_max_w:\n",
        "        im = crop_resize(im, (-1,bg_mode_max_w))\n",
        "      imageio.imwrite(os.path.join(out_dir, file if is_pre else 'frame_%05d.png'%i), np.uint8(im*255), compression=1 if len(fg_files)>1 or bg_files else 9, format='PNG-FI')\n",
        "      print('%d/%d (%d)'%(i+1,len(iter_files),rounds))\n",
        "  blend_time += time()-start\n",
        "\n",
        "out_dir = result_dir\n",
        "bg_mode = background_url\n",
        "if 'u2net_portrait' in model:\n",
        "  out_dir = portrait_in_dir\n",
        "  bg_mode = 'white' \n",
        "if model!='u2net_portrait':\n",
        "  mat(fg_dir, out_dir, bg_mode, is_pre='+' in model)\n",
        "elif 'u2net_portrait' in model:\n",
        "  if background_url=='foreground' or sketch_color!='gray':\n",
        "    !cp $fg_dir/* $portrait_in_dir\n",
        "  else:\n",
        "    !mv $fg_dir/* $portrait_in_dir\n",
        "if 'u2net_portrait' in model:\n",
        "  %cd /content/U-2-Net\n",
        "  start = time()\n",
        "  !python /content/U-2-Net/u2net_portrait_test.py\n",
        "  blend_time += time()-start\n",
        "  if type(background_url)==list or background_url=='foreground' or sketch_color!='gray':\n",
        "    mat(portrait_out_dir, result_dir, background_url, orig_dir=fg_dir if background_url=='foreground' or sketch_color!='gray' else None)\n",
        "  else:\n",
        "    !mv $portrait_out_dir/* $result_dir\n",
        "\n",
        "start = time()\n",
        "from IPython.display import HTML, clear_output, Image\n",
        "from base64 import b64encode\n",
        "import shutil\n",
        "!rm -f /content/final.mp4\n",
        "!rm -f /content/final.png\n",
        "if len(fg_files)>1 or len(bg_files)>1:\n",
        "  if is_fg:\n",
        "    if copy_audio:\n",
        "      !ffmpeg -framerate $override_fps -i $result_dir/frame_%05d.png $fg_time_params -i /content/foreground -c:v libx264 -c:a aac -map 0:v -map 1:a? -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p -profile:v baseline -movflags +faststart /content/final.mp4 -y\n",
        "    else:\n",
        "      !ffmpeg -framerate $override_fps -i $result_dir/frame_%05d.png -c:v libx264 -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p -profile:v baseline -movflags +faststart /content/final.mp4 -y\n",
        "  else:\n",
        "    if copy_audio:\n",
        "      with open('/content/list.txt','w') as f:\n",
        "        if bg_time_params:\n",
        "          start_seconds = float(bg_time_params.split(' ')[1])\n",
        "          end_seconds = start_seconds + float(bg_time_params.split(' ')[3])\n",
        "        for file in background_url:\n",
        "          f.write(\"file '%s'\\n\"%file)\n",
        "          if bg_time_params:\n",
        "            f.write('inpoint %f\\n'%start_seconds)\n",
        "            f.write('outpoint %f\\n'%end_seconds)\n",
        "      !ffmpeg -f concat -safe 0 -i /content/list.txt -c copy /content/bg_audio.mp4 -y\n",
        "      !ffmpeg -framerate $override_fps -i $result_dir/frame_%05d.png -i /content/bg_audio.mp4 -c:v libx264 -c:a aac -map 0:v -map 1:a? -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p -profile:v baseline -movflags +faststart /content/final.mp4 -y\n",
        "    else:\n",
        "      !ffmpeg -framerate $override_fps -i $result_dir/frame_%05d.png -c:v libx264 -c:a aac -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p -profile:v baseline -movflags +faststart /content/final.mp4 -y\n",
        "  #video can be downloaded from /content/final.mp4\n",
        "  save_time = time()-start\n",
        "  total_time = time()-grand_start  \n",
        "  clear_output()\n",
        "  with open('/content/final.mp4', 'rb') as f:\n",
        "    data_url = \"data:video/mp4;base64,\" + b64encode(f.read()).decode()\n",
        "  display(HTML(\"\"\"\n",
        "  <video width=600 controls autoplay loop>\n",
        "        <source src=\"%s\" type=\"video/mp4\">\n",
        "  </video>\"\"\" % data_url))\n",
        "else:\n",
        "  shutil.move(os.path.join(out_dir,'frame_%05d.png'%1), '/content/final.png')\n",
        "  #image can be downloaded from /content/final.png\n",
        "  save_time = time()-start\n",
        "  total_time = time()-grand_start\n",
        "  clear_output()\n",
        "  display(Image('/content/final.png', width=600))\n",
        "if model.startswith('u2net'):\n",
        "    print('frames=%d prepare=%d mask=%d blend=%d save=%d total=%d'%(len(iter_files), prepare_time, mask_time, blend_time, save_time, total_time))\n",
        "else:\n",
        "    print('frames=%d prepare=%d mask+blend=%d save=%d total=%d'%(len(iter_files), prepare_time, mask_time+blend_time, save_time, total_time))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxy4hscknBvt",
        "cellView": "form"
      },
      "source": [
        "#@title Download\n",
        "from google.colab import files\n",
        "if os.path.exists('/content/final.mp4'):\n",
        "  files.download('/content/final.mp4')\n",
        "else:\n",
        "  files.download('/content/final.png')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}