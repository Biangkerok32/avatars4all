{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "melaflefon.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/avatars4all/blob/master/melaflefon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "802K_fw2kLbV"
      },
      "source": [
        "# Wav2Lip Demo Colab\n",
        "\n",
        "### Made just a little bit more accessible by Eyal Gruss (https://eyalgruss.com, eyalgruss@gmail.com)\n",
        "\n",
        "##### Original project: http://bhaasha.iiit.ac.in/lipsync\n",
        "\n",
        "##### Original notebook: https://colab.research.google.com/drive/1tZpDWXz49W6wDcTprANRGLo2D_EbD5J8\n",
        "\n",
        "##### Combined with First Order Motion Model: https://colab.research.google.com/github/eyaler/avatars4all/blob/master/fomm_bibi.ipynb\n",
        "\n",
        "##### Speaker diarization with: https://github.com/tyiannak/pyAudioAnalysis,  https://github.com/pyannote/pyannote-audio\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3LihClHbUd3",
        "cellView": "form"
      },
      "source": [
        "#@title Dub it!\n",
        "#@markdown 1. Choose audio (you can also enter a YouTube or similar URL, or a manually uploaded file name):\n",
        "audio = 'Dangerous time' #@param ['Dangerous time', 'Go home', 'Sound of victory', 'Ernie and Bert', 'מלפפונים חמוצים', 'שונאת שמאלנים', 'אני שולה', 'אריק ובנץ', 'אריק ובנץ וגנץ', 'Grab from uploaded video'] {allow-input: true}\n",
        "#@markdown 2. Optionally tick switch_speakers to switch between visual media files with the change of speakers:\n",
        "switch_speakers = False #@param {type: \"boolean\"}\n",
        "#@markdown 3. Choose model for speaker diarization:\n",
        "model = 'pyannote-audio DIHARD' #@param ['pyAudioAnalysis', 'pyannote-audio DIHARD','pyannote-audio AMI']\n",
        "#@markdown 4. Optionally tick reuse_files if you want to reuse previously uploaded files:\n",
        "reuse_files = False #@param {type: \"boolean\"}\n",
        "#@markdown 5. Press the play (triangle) button on the left\n",
        "#@markdown 6. Press \"Browse\" below, and upload image(s) or video(s) (if not reusing files)\n",
        "\n",
        "from google.colab import files\n",
        "try:\n",
        "  inputs\n",
        "except NameError:\n",
        "  reuse_files = False\n",
        "\n",
        "if not reuse_files:\n",
        "  %cd /content/sample_data\n",
        "  !rm -rf *\n",
        "  inputs = files.upload()\n",
        "\n",
        "if inputs:\n",
        "  %tensorflow_version 1.x\n",
        "  %cd /content\n",
        "  !pip install pyannote.audio==1.1.1\n",
        "  !pip install hmmlearn==0.2.2\n",
        "  !pip install eyeD3==0.9.5\n",
        "  !pip install pydub==0.24.0\n",
        "  !pip install pyAudioAnalysis\n",
        "  !git clone --depth 1 https://github.com/eyaler/Wav2Lip.git\n",
        "  import os\n",
        "  if not os.path.exists('/content/Wav2Lip/checkpoints/wav2lip_gan.pth'):\n",
        "    !gdown https://drive.google.com/uc?id=1dwHujX7RVNCvdR1RR93z0FS2T2yzqup9 -O /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
        "  !wget --no-check-certificate -nc https://eyalgruss.com/fomm/wav2lip_gan.pth -O /content/Wav2Lip/checkpoints/wav2lip_gan.pth\n",
        "  !wget --no-check-certificate -nc https://eyalgruss.com/fomm/melaflefon.mp3\n",
        "  !wget --no-check-certificate -nc https://eyalgruss.com/fomm/sonet.mp3\n",
        "  !wget --no-check-certificate -nc https://eyalgruss.com/fomm/shoula.mp3\n",
        "  !wget --no-check-certificate -nc https://eyalgruss.com/fomm/gohome.mp3\n",
        "  !wget --no-check-certificate -nc https://eyalgruss.com/fomm/s3fd-619a316812.pth -O /content/Wav2Lip/face_detection/detection/sfd/s3fd.pth\n",
        "  !pip install -U youtube-dl\n",
        "  if not os.path.exists('/content/dangerous.mp3'):\n",
        "    !youtube-dl --extract-audio --audio-format mp3 https://www.youtube.com/watch?v=cQ54GDm1eL0 -o /content/dangerous.mp3\n",
        "  if not os.path.exists('/content/victory.mp3'):\n",
        "    !youtube-dl --extract-audio --audio-format mp3 https://www.youtube.com/watch?v=Nu96Fhl1Gjo -o /content/victory.mp3\n",
        "  if not os.path.exists('/content/dialog_eng.mp3'):\n",
        "    !youtube-dl --extract-audio --audio-format mp3 https://www.youtube.com/watch?v=I78YAciQpr0 -o /content/dialog_eng.mp3\n",
        "  if not os.path.exists('/content/dialog_heb.mp3'):\n",
        "    !youtube-dl --extract-audio --audio-format mp3 https://www.youtube.com/watch?v=rrZ3bo4VmpQ -o /content/dialog_heb.mp3\n",
        "  if not os.path.exists('/content/trialog_heb.mp3'):\n",
        "    !youtube-dl --extract-audio --audio-format mp3 https://www.youtube.com/watch?v=HOKJnkG5MXQ -o /content/trialog_heb.mp3\n",
        "  grab = False\n",
        "  manual = False\n",
        "  if '://' in audio:\n",
        "    if os.path.exists('/content/custom.mp3'):\n",
        "      os.remove('/content/custom.mp3')\n",
        "    !youtube-dl --extract-audio --audio-format mp3 '$audio' -o /content/custom.mp3\n",
        "    audio = 'custom'\n",
        "  elif audio=='Dangerous time':\n",
        "    audio = 'dangerous'\n",
        "  elif audio=='Go home':\n",
        "    audio = 'gohome'\n",
        "  elif audio=='Sound of victory':\n",
        "    audio = 'victory'\n",
        "  elif audio=='Ernie and Bert':\n",
        "    audio = 'dialog_eng'\n",
        "  elif audio == 'מלפפונים חמוצים':\n",
        "    audio = 'melaflefon'\n",
        "  elif audio == 'שונאת שמאלנים':\n",
        "    audio = 'sonet'\n",
        "  elif audio == 'אני שולה':\n",
        "    audio = 'shoula'\n",
        "  elif audio == 'אריק ובנץ':\n",
        "    audio = 'dialog_heb'\n",
        "  elif audio == 'אריק ובנץ וגנץ':\n",
        "    audio = 'trialog_heb'\n",
        "  elif audio == 'Grab from uploaded video':\n",
        "    grab = True\n",
        "  elif audio == '':\n",
        "    audio = 'custom'\n",
        "  else:\n",
        "    manual = True\n",
        "  audio = '/content/'+audio\n",
        "  if not manual or not os.path.exists(audio):\n",
        "    audio += '.mp3'\n",
        "\n",
        "  %cd /content/Wav2Lip\n",
        "  outputs = []\n",
        "  for im in inputs:\n",
        "    infile = '/content/sample_data/'+im\n",
        "    ext = infile.rsplit('.',1)[1]\n",
        "    if ext != ext.lower() or \"'\" in infile:\n",
        "      lower = infile.rsplit('.',1)[0].replace(\"'\",'')+'.'+ext.lower()\n",
        "      os.rename(infile, lower)\n",
        "      infile = lower\n",
        "      ext = ext.lower()\n",
        "    outfile = '/content/'+im.rsplit('.',1)[0].replace(\"'\",'')+'_out.mp4'\n",
        "    if grab:\n",
        "      audio = infile\n",
        "    !python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face '$infile' --audio '$audio' --pads 0 20 0 0 --outfile \\\"'$outfile'\\\" 2>&1 | tee /content/out.txt\n",
        "    bad = !cat /content/out.txt | grep 'Face not detected'\n",
        "    if bad:\n",
        "      import cv2\n",
        "      print('\\nFace not detected - will use whole frame')\n",
        "      if ext in ['jpg', 'png', 'jpeg']:\n",
        "        frame = cv2.imread(infile)\n",
        "      else:\n",
        "        video_stream = cv2.VideoCapture(infile)\n",
        "        still_reading, frame = video_stream.read()\n",
        "      x1 = 0\n",
        "      h,x2 = frame.shape[:2]\n",
        "      if x2>h:\n",
        "        x1 = (x2-h)//2\n",
        "        x2 = x1+h\n",
        "      !python inference.py --checkpoint_path checkpoints/wav2lip_gan.pth --face '$infile' --audio '$audio' --box 0 $h $x1 $x2 --pads 0 20 0 0 --outfile \\\"'$outfile'\\\"\n",
        "    outputs.append(outfile)\n",
        "\n",
        "  wav = None\n",
        "  if switch_speakers and len(outputs)>1 and not grab:\n",
        "    wav = audio.rsplit('.mp3',1)[0]+'.wav'\n",
        "    !ffmpeg -i $audio $wav -y\n",
        "    min_dt = 0.5\n",
        "    if model.startswith('pyannote-audio'):\n",
        "      import torch\n",
        "      import pyannote.core #https://github.com/pyannote/pyannote-audio/issues/561\n",
        "      from pyannote.audio.features.utils import get_audio_duration\n",
        "      if model.endswith('AMI'):\n",
        "        pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia_ami')\n",
        "      else:\n",
        "        pipeline = torch.hub.load('pyannote/pyannote-audio', 'dia')\n",
        "      cls = pipeline({'audio':wav})\n",
        "      tmp_segs = [((s.start,s.end),l) for s,_,l in cls.itertracks(yield_label=True)]\n",
        "      segs = []\n",
        "      prev_ind = None \n",
        "      prev_start = None\n",
        "      for (start,end),ind in tmp_segs+[((get_audio_duration({'audio':wav}),None),None)]:\n",
        "        if ind!=prev_ind:\n",
        "          if prev_ind is not None:\n",
        "            segs.append([(prev_start,start),prev_ind])\n",
        "          prev_ind = ind\n",
        "          prev_start = start\n",
        "    elif model=='pyAudioAnalysis':\n",
        "      from pyAudioAnalysis import audioSegmentation as aS\n",
        "      mid_window=2\n",
        "      mid_step=0.2\n",
        "      short_window=0.05\n",
        "      lda_dim=0 #35\n",
        "      cls = aS.speaker_diarization(wav, len(outputs), mid_window=mid_window, mid_step=mid_step, short_window=short_window, lda_dim=lda_dim)\n",
        "      segs = list(zip(*aS.labels_to_segments(cls, mid_step)))\n",
        "    deleted = 0\n",
        "    unified = 0\n",
        "    if min_dt:\n",
        "      for i in range(len(segs)-1,0,-1):\n",
        "        if segs[i][0][1]-segs[i][0][0]<min_dt:\n",
        "          if i+1<len(segs) and segs[i-1][1] == segs[i+1][1]:\n",
        "            segs[i-1] = ((segs[i-1][0][0],segs[i+1][0][1]),segs[i-1][1])\n",
        "            del segs[i+1]\n",
        "            unified += 1\n",
        "          else:\n",
        "            segs[i-1] = ((segs[i-1][0][0],segs[i][0][1]),segs[i-1][1])\n",
        "          del segs[i]\n",
        "          deleted += 1\n",
        "    inds = {}\n",
        "    my_ind = 0\n",
        "    with open('/content/list.txt','w',encoding='utf8') as f:\n",
        "      for i,((start,end),ind) in enumerate(segs):\n",
        "        if ind not in inds:\n",
        "          inds[ind] = my_ind%len(outputs)\n",
        "          my_ind += 1\n",
        "        f.write(\"file '%s'\\n\"%outputs[inds[ind]])\n",
        "        if i>0:\n",
        "          f.write('inpoint %f\\n'%start)\n",
        "        if i<len(segs)-1:\n",
        "          f.write('outpoint %f\\n'%end)\n",
        "    !ffmpeg -f concat -safe 0 -i /content/list.txt -i \"{outputs[0]}\" -map 0:v -map 1:a -c:v libx264 -c:a aac -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p -profile:v baseline -movflags +faststart /content/combined.mp4 -y\n",
        "    new_outputs = ['/content/combined.mp4']\n",
        "    if len(outputs)==2:\n",
        "      with open('/content/list2.txt','w',encoding='utf8') as f:\n",
        "        for i,((start,end),ind) in enumerate(segs):\n",
        "          f.write(\"file '%s'\\n\"%outputs[1-inds[ind]])\n",
        "          if i>0:\n",
        "            f.write('inpoint %f\\n'%start)\n",
        "          if i<len(segs)-1:\n",
        "            f.write('outpoint %f\\n'%end)\n",
        "      !ffmpeg -f concat -safe 0 -i /content/list2.txt -i \"{outputs[1]}\" -map 0:v -map 1:a -c:v libx264 -c:a aac -vf \"crop=trunc(iw/2)*2:trunc(ih/2)*2\" -pix_fmt yuv420p -profile:v baseline -movflags +faststart /content/combined2.mp4 -y\n",
        "      new_outputs.append('/content/combined2.mp4')\n",
        "    outputs = new_outputs\n",
        "\n",
        "  from IPython.display import HTML, clear_output\n",
        "  from base64 import b64encode\n",
        "\n",
        "  clear_output()\n",
        "  muted = 'muted'\n",
        "  for i,file in enumerate(reversed(outputs)):\n",
        "    if i==len(outputs)-1:\n",
        "      muted = ''\n",
        "    with open(file, 'rb') as f:\n",
        "      data_url = \"data:video/mp4;base64,\" + b64encode(f.read()).decode()\n",
        "    display(HTML(\"\"\"\n",
        "    <video width=600 controls autoplay loop %s>\n",
        "          <source src=\"%s\" type=\"video/mp4\">\n",
        "    </video>\"\"\" % (muted,data_url)))\n",
        "  if wav:\n",
        "    print('speakers=%d segments=%d deleted=%d unified=%d'%(len(inds), len(segs),deleted,unified))\n",
        "  for file in outputs:\n",
        "    try:\n",
        "      files.download(file)\n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}